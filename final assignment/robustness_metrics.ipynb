{
 "cells": [
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from SALib.analyze import sobol\n",
    "import warnings\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from optimization_tuned import (epsilon_nondominated,HypervolumeMetric, Hypervolume, ArchiveLogger, \n",
    "                                AbstractConvergenceMetric, EpsilonProgress)\n",
    "\n",
    "from optimization_tuned import epsilon_nondominated, to_problem\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    perform_experiments,\n",
    "    Samplers,\n",
    "    SequentialEvaluator,\n",
    "    ScalarOutcome\n",
    ")\n",
    "from dike_model_function import DikeNetwork\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "from ema_workbench.analysis import prim\n",
    "from ema_workbench.em_framework.parameters import Constant\n",
    "#from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, SequentialEvaluator,\n",
    "                           Scenario, Policy, perform_experiments, ema_logging)\n",
    "from ema_workbench.em_framework.optimization import HyperVolume\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "5814a37c561bd01b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Robustness Metrics"
   ],
   "id": "4c77cacf6f63ce90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## General setup"
   ],
   "id": "262a4369a8b89a4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setup using DB results"
   ],
   "id": "1c2496909ffdbdcd"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Defining the model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(6)"
   ],
   "id": "739f5f1e9dab5550",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Load results coming from Delft Blue for scenario 0\n",
    "scenario_0_results = []\n",
    "for i in range(6):\n",
    "    with open(f\"DB_results\\Seed-{i}Scen-0.pkl\", 'rb') as file:\n",
    "        seed_result = pickle.load(file)\n",
    "        scenario_0_results.append(seed_result[0])\n",
    "        \n",
    "#Load results coming from Delft Blue for scenario 1      \n",
    "scenario_1_results = []\n",
    "for i in range(6):\n",
    "    with open(f\"DB_results\\Seed-{i}Scen-1.pkl\", 'rb') as file:\n",
    "        seed_result = pickle.load(file)\n",
    "        scenario_1_results.append(seed_result[0])\n"
   ],
   "id": "d4fdd0c1fc746cf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [],
   "id": "b66f581bdf447c36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Defining the problem\n",
    "problem = to_problem(dike_model, searchover=\"levers\")"
   ],
   "id": "1d627fb9f09fd345",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Make sure only the relevant policies coming from Open Exploration are taken into account in both the problem and the dike_model\n",
    "\n",
    "levers_to_delete = [\"A.1_DikeIncrease 0\",\"A.1_DikeIncrease 1\",\"A.1_DikeIncrease 2\",\"A.2_DikeIncrease 0\",\n",
    "                    \"A.2_DikeIncrease 1\",\"A.2_DikeIncrease 2\",\"A.3_DikeIncrease 1\",\"A.3_DikeIncrease 2\",\"A.4_DikeIncrease 0\",\n",
    "                    \"A.4_DikeIncrease 1\",\"A.4_DikeIncrease 2\",\"A.5_DikeIncrease 2\",\"0_RfR 0\",\"0_RfR 1\",\"0_RfR 2\",\"1_RfR 0\",\n",
    "                    \"1_RfR 1\",\"1_RfR 2\",\"4_RfR 0\",\"4_RfR 1\",\"4_RfR 2\"]\n",
    "\n",
    "for lever in levers_to_delete:\n",
    "    problem.parameters.__delitem__(lever)\n",
    "\n",
    "#Update the number of levers of the problem instance, because somehow this does not get updated automatically\n",
    "problem.nvars = 10"
   ],
   "id": "7b3e19af3ad0be5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Merge Seeds"
   ],
   "id": "471401118b657a9b"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Merge the results from the different seeds for each scenario\n",
    "#epsilons = [0.1, 0.1, 10000, 0.1, 10000, 0.1]\n",
    "epsilons = [0.05] * len(dike_model.outcomes)\n",
    "\n",
    "merged_results_0 = epsilon_nondominated(scenario_0_results, epsilons, problem)\n",
    "\n",
    "merged_results_1 = epsilon_nondominated(scenario_1_results, epsilons, problem)"
   ],
   "id": "30e69e7ff0827def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Remove duplicate candidate strategies from the two scenarios"
   ],
   "id": "b447337a480e66d"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "merged_results = pd.concat([merged_results_0, merged_results_1], axis=0)"
   ],
   "id": "11534ecaecb4cbb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "unique_results = merged_results.drop_duplicates(subset=merged_results.columns[:10])"
   ],
   "id": "379430e5295724bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Policy setup\n",
    "\n"
   ],
   "id": "9e17e9df8f95fd12"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#We add manual constraints, as we want 0 deaths in dike ring 5 and no evacuation, so no evacuation costs\n",
    "filter = (#(merged_results['A.5_Expected Number of Deaths'] < 0.001) & \n",
    "          #(merged_results['EWS_DaysToThreat'] <= 1 ) & \n",
    "          (merged_results['Expected Evacuation Costs'] < 0.001))\n",
    "\n",
    "#We add the constraint of EWS to be max 1 day, in order to minimize evacuation\n",
    "#Minimizing evacuation costs gave too little candidate strategies\n",
    "policies = merged_results[filter]\n",
    "\n",
    "#Just keep in the policies, and get rid of the outcomes\n",
    "policies = policies.drop([o.name for o in dike_model.outcomes], axis=1)\n",
    "policies = policies.reset_index(drop=True)"
   ],
   "id": "9343b160d1064b3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [],
   "id": "25f254e55b9e88ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policy = {str(p): 0 for p in dike_model.levers}\n",
    "\n",
    "policies_to_evaluate = []\n",
    "for index, row in policies.iterrows():\n",
    "    for p in policies.columns:\n",
    "        policy[p] = row[p]\n",
    "    policies_to_evaluate.append(Policy(f'Policy{index}', **policy))"
   ],
   "id": "88c598df797b3d3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "##############Old code to create policy objects, only with selected levers from OE\n",
    "\n",
    "#Create Policy objects\n",
    "# policies_to_evaluate2 = []\n",
    "# \n",
    "# for i, policy in policies.iterrows():\n",
    "#     policies_to_evaluate2.append(Policy(str(i), **policy.to_dict()))\n",
    "policies"
   ],
   "id": "fc0fa33856c1d52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "# Run 1000 scenarios for each of the policy options\n",
    "\n",
    "n_scenarios = 3000\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            policies_to_evaluate)"
   ],
   "id": "fd58df89d30812d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Signal to Noise ratio"
   ],
   "id": "b8a026f950da8360"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [],
   "id": "7258dcb80f995600",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "source": [
    "#For an outcome indicator to be minimized, a lower mean and a lower standard deviation is preferred.\n",
    "#We want all our signal to noise ratios to be minimized\n",
    "\n",
    "def s_to_n(data, direction):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "experiments, outcomes = results"
   ],
   "id": "bfa358223357b33d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Saving the results just to be sure\n",
    "outcomes2 = pd.DataFrame.from_dict(outcomes)\n",
    "outcomes2.to_csv('DB_results/outcomes_robustness.csv')\n",
    "experiments.to_csv('DB_results/experiments_robustness.csv')"
   ],
   "id": "a123ef2f5bccddbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "overall_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in dike_model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n"
   ],
   "id": "109398f3dc47d3f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = scores\n",
    "\n",
    "# Normalizing the data\n",
    "zero_columns = data.columns[(data == 0).all()]\n",
    "data_normalized = data.copy()\n",
    "for col in data.columns:\n",
    "    if col not in zero_columns:\n",
    "        data_normalized[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "\n",
    "#Plotting the data\n",
    "limits = parcoords.get_limits(data_normalized)\n",
    "limits.loc[0, ['A.5_Expected Number of Deaths', 'A.5_Expected Annual Damage', 'Expected Evacuation Costs',\n",
    "               'Expected Annual Damage', 'Total Investment Costs', 'Expected Number of Deaths']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data_normalized)\n",
    "plt.show()"
   ],
   "id": "99fe5ea7c80ed630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = scores\n",
    "\n",
    "#Plotting the non-normalized data\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['A.5_Expected Number of Deaths', 'A.5_Expected Annual Damage', 'Expected Evacuation Costs',\n",
    "               'Expected Annual Damage', 'Total Investment Costs', 'Expected Number of Deaths']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "plt.show()"
   ],
   "id": "2678a05ebd4294f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Plotting with seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "data1 = scores.copy()\n",
    "\n",
    "# Normalize the data \n",
    "zero_columns = data1.columns[(data1 == 0).all()]\n",
    "data_normalized1 = data1.copy()\n",
    "for col in data.columns:\n",
    "    if col not in zero_columns:\n",
    "        data_normalized1[col] = (data1[col] - data1[col].min()) / (data1[col].max() - data1[col].min())\n",
    "\n",
    "data_normalized1['class'] = ['Policy ' + str(i) for i in range(len(data_normalized1))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "parallel_coordinates(data_normalized1, 'class', colormap=plt.get_cmap(\"Set1\"))\n",
    "\n",
    "plt.title(\"Parallel Coordinates Plot Signal to Noise Ratio\")\n",
    "plt.xlabel(\"Outcomes\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Rotate x-axis labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Move legend to the right side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "plt.grid(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ],
   "id": "9add18fa8a83f0ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regret"
   ],
   "id": "349224e08ee51adb"
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "#Function to calculate regret\n",
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ],
   "id": "b7e386a8ce6087aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in dike_model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1).values[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ],
   "id": "281bcd6635e35ba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret / max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()\n"
   ],
   "id": "b3eacc5bb172b958",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "data = max_regret\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(data))\n",
    "\n",
    "# Normalizing the data\n",
    "zero_columns = data.columns[(data == 0).all()]\n",
    "data_normalized = data.copy()\n",
    "for col in data.columns:\n",
    "    if col not in zero_columns:\n",
    "        data_normalized[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "# in the parcoords plot\n",
    "# data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data_normalized)\n",
    "limits.loc[0, ['A.5_Expected Number of Deaths', 'A.5_Expected Annual Damage', 'Expected Evacuation Costs',\n",
    "               'Expected Annual Damage', 'Total Investment Costs', 'Expected Number of Deaths']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data_normalized.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ],
   "id": "3402bdfaeedd9e5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "data = max_regret.copy()\n",
    "\n",
    "plt.style.use({'figure.facecolor': 'white'})\n",
    "\n",
    "# Normalize the data \n",
    "zero_columns = data.columns[(data == 0).all()]\n",
    "data_normalized = data.copy()\n",
    "for col in data.columns:\n",
    "    if col not in zero_columns:\n",
    "        data_normalized[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "data_normalized['class'] = ['Policy ' + str(i) for i in range(len(data_normalized))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "parallel_coordinates(data_normalized, 'class', colormap=plt.get_cmap(\"Set1\"))\n",
    "\n",
    "plt.title(\"Parallel Coordinates Plot Max Regret\")\n",
    "plt.xlabel(\"Outcomes\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "# Rotate x-axis labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Move legend to the right side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "plt.grid(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ],
   "id": "203e13ae8182ee94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "policy_regret = defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ],
   "id": "f18deb2deff26806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "# this generates a 2 plots with a shared y and x axis\n",
    "fig, axes = plt.subplots(ncols=22,nrows=1, figsize=(40,5), \n",
    "                         sharey=True, sharex=True)\n",
    "\n",
    "# to ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Because there are four plots, I hard coded\n",
    "# this. \n",
    "\n",
    "\n",
    "# zip allows us to zip together the list of axes and the list of \n",
    "# key value pairs return by items. If we iterate over this\n",
    "# it returns a tuple of length 2. The first item is the ax\n",
    "# the second items is the key value pair.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # we need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by divding by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "    \n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "    \n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "    \n",
    "    # Rotate x-axis labels vertically\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    \n",
    "plt.show()"
   ],
   "id": "8f9cef49f2089807",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
